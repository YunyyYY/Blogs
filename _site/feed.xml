<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yunyy</title>
    <description>Yunyy's Notes, 流水账和七拼八凑的时间碎片。</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Perplexity</title>
        <description>&lt;h2 id=&quot;perplexity-困惑度&quot;&gt;Perplexity 困惑度&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Reference: &lt;a href=&quot;https://blog.csdn.net/jiaqiang_ruan/article/details/77989459&quot;&gt;CSDN Perplexity(困惑度)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;概率分布的困惑度&quot;&gt;概率分布的困惑度&lt;/h3&gt;

&lt;p&gt;离散概率分布的困惑度定义为：
&lt;script type=&quot;math/tex&quot;&gt;2^{H(p)}, \hspace.5cm H(p) = -\sum_{x} p(x) \log _{2} p(x)&lt;/script&gt;
$H(p)$是概率分布$p$的熵，$x$是样本点。因此一个随机变量$X$的困惑度是定义在$X$的概率分布上的（$X$所有可能取值）。&lt;/p&gt;

&lt;p&gt;困惑度是信息熵的指数。&lt;/p&gt;

&lt;h3 id=&quot;概率模型的困惑度&quot;&gt;概率模型的困惑度&lt;/h3&gt;

&lt;p&gt;用一个概率模型$q$去估计真实概率分布$p$，可以通过&lt;strong&gt;测试集&lt;/strong&gt;中的样本来定义这个概率模型的困惑度。
&lt;script type=&quot;math/tex&quot;&gt;b^{-\frac{1}{N}\sum_{i=1}^{N} \log _{b} q\left(x_{i}\right)}&lt;/script&gt;
其中测试样本$x_1$, $x_2$, …, $x_N$是来自于真实概率分布$p$的观测值，$b$通常取2。因此，低的困惑度表示$q$对$p$拟合的越好，当模型$q$看到测试样本时，它会不会感到那么“困惑”。&lt;/p&gt;
</description>
        <pubDate>Sat, 04 Jan 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/notes/perplexity/</link>
        <guid isPermaLink="true">http://localhost:4000/notes/perplexity/</guid>
      </item>
    
      <item>
        <title>牡丹亭</title>
        <description>&lt;h4 id=&quot;注释&quot;&gt;注释&lt;/h4&gt;

&lt;ol&gt;
  &lt;li&gt;标目： 传奇的第一齣（chu，出的繁体字），照例说明：戏曲的创作缘起和剧情梗概，原称“家门印子”。&lt;/li&gt;
  &lt;li&gt;末：年纪较大的男性角色，传奇第一出一般由副末开场，本剧末代替副末。&lt;/li&gt;
  &lt;li&gt;生：传奇的男主角，相当于元代杂剧的正末。男角除生外，还有末、外、净、丑等。&lt;/li&gt;
  &lt;li&gt;玉茗花：白山茶&lt;/li&gt;
  &lt;li&gt;黄堂：太守&lt;/li&gt;
  &lt;li&gt;踏春阳：踏青&lt;/li&gt;
  &lt;li&gt;高唐、云雨、巫山、阳台、楚台，指男女欢会。出自宋玉《高唐赋》。引楚怀王传说。亦见《夜航船》天文部风云篇“行云”。&lt;/li&gt;
  &lt;li&gt;香火秀才：奉祀生，“圣贤”之后，不经科举考试，赐予秀才之，管理先祖祠庙的祭祀。&lt;/li&gt;
  &lt;li&gt;随喜：游览寺院&lt;/li&gt;
  &lt;li&gt;萱花椿树：指父母。萱花即忘忧草，椿树以长寿著称。&lt;/li&gt;
  &lt;li&gt;西宾，西席：指代塾师。&lt;/li&gt;
  &lt;li&gt;菱花：镜子&lt;/li&gt;
  &lt;li&gt;锦屏人：深闺中人&lt;/li&gt;
  &lt;li&gt;秦晋：秦晋之好即联姻。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;####言怀&lt;/p&gt;

&lt;p&gt;梦长梦短俱是梦，年来年去是何年！&lt;/p&gt;

&lt;h4 id=&quot;惊梦&quot;&gt;惊梦&lt;/h4&gt;

&lt;p&gt;不到游园，怎知春色如许！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;原来姹紫嫣红开遍，似这般都付与断井残垣。良辰美景奈何天，赏心乐事谁家院。朝飞暮卷，云霞翠轩；雨丝风片，烟波画船——锦屏人忒看的这韶光贱。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;忒，（tui，一声， “太”的意思）&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;天下良辰美景赏心乐事，四者难并。（谢灵运《拟魏太子邺中集诗序》&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;遍青山啼红了杜鹃，荼蘼外烟丝醉软。牡丹虽好，他春归怎占的先。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;则为你如花美眷，似水流年，是答儿闲寻遍。在幽闺自怜。&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Jan 2020 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sougua/%E7%89%A1%E4%B8%B9%E4%BA%AD/</link>
        <guid isPermaLink="true">http://localhost:4000/sougua/%E7%89%A1%E4%B8%B9%E4%BA%AD/</guid>
      </item>
    
      <item>
        <title>夜航船</title>
        <description>&lt;h4 id=&quot;天文部-风云&quot;&gt;天文部 风云&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;少女风&lt;/strong&gt; 管辂过清河，倪太守以天旱为忧。辂曰：“树上已有少女微风，树间已有阴鸟和鸣。其雨至矣。”果如其言。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;《管辂别传》：“树上已有少女微风，树间又有阴鸟和鸣。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;卿云&lt;/strong&gt; 云，五色为卿，三色为矞。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;《春秋繁露》：“人君修德，则矞云见。”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;云霞&lt;/strong&gt; 云，山川之气也。日旁彩云名霞，东西二方赤色，亦曰霞。《易经》：“云从龙，风从虎。”&lt;/p&gt;
</description>
        <pubDate>Sun, 29 Dec 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sougua/%E5%A4%9C%E8%88%AA%E8%88%B9/</link>
        <guid isPermaLink="true">http://localhost:4000/sougua/%E5%A4%9C%E8%88%AA%E8%88%B9/</guid>
      </item>
    
      <item>
        <title>忒修斯之船</title>
        <description>&lt;p&gt;人会迷路，人会消失，人会被抹去然后重生。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他觉得好像再次坠落，坠穿黑暗，除了地心引力的残酷效率之外，再也不能相信什么。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;人都会逃离改变，直到再也没有别的路可以选择。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;今晚，这是他们的家。&lt;/p&gt;

&lt;p&gt;明天呢？明天的事谁说的准？&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;恐惧的力量很强大，就连强悍的人也会屈服。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他的失忆倒成了一桩幸事：他不知道自己与他人有任何关系，也因此没有让他害怕会断绝的关系，没有断绝后需要修补的关系，没有失去后会令他伤心的关系。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;“那本书还在你们家族的手上吗？”
“没有。被偷了。美好的事物多半会有此下场。”&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;艺术品也是如此，但还有：青春、人生、地位、隐私、心爱的人、机会、自由表达、信念、尊重和名誉。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;在他还没能决定该如何弥补过失之前，那如同时间本身规律而不间断的水滴声，又哄着心跳怦然、羞愧感冻结的他昏昏睡去。慈悲的水呀。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;
      &lt;p&gt;“创作艺术必须沦落入黑暗中。”&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;痛苦必然是一种个人体验。&lt;/p&gt;
    &lt;/li&gt;
    &lt;li&gt;
      &lt;p&gt;我们是出于私利而追求关系的吗？&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他的话还能激励谁去采取正义行动呢？那群一闪即逝的银白飞鱼吗？风吗？月亮吗？已与他形同陌路的星星吗？&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;那颗子弹被她残余的生命包覆住，速度骤减落入浪涛中，要破坏它的杀伤力已经太迟，但记忆永远无法抹灭。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他们快速地老化，他们的身体一致地衰退，思绪一齐变得模糊，在等待未知的未来时，彼此的恐惧也连成一体。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;是他想象出这个孩子，暗喻一个许诺的人生，一个他从未有过的人生。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;她出现在这里真让人吃惊。还有一件事也几乎同样令他吃惊，那就是她清晰、鲜明、温热、有呼吸，无可否认地真实。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他忽然害怕她会再次消失，害怕他们会继续变老，而且可能分别死去。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他知道自己曾经很在乎，也觉得似乎应该在乎。曾经有许多年，他以为自己在乎，却几乎没有认真地去追查过真相。这个秘密不再令他动心。比起记录着他的人生真相，但早已被遗忘的官方文件，这些真相本身并不是更重要。那么回忆呢？身为家庭一份子的感觉呢？童年的感官印象呢？还有日复一日地为铜制弹壳装填火药的青少年，在开始认清真实世界时所感受到的小小领悟与心碎呢？他在船上的恍惚状态中、在严寒的公寓里都体验过这些，也许无法拥有，但那些时刻环绕在他身旁，偶尔也可能闪闪发亮。他可以看见星星，但他已不再需要星座。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;问为什么就好像问天空为什么在头顶上，星星为什么在更远的地方。这些的确是好问题，可是没有答案，到了某个时候，我们就会选择不再问了。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;第一遍：&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;《忒修斯之船》每一章的原文和注释&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;第二遍：&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;埃里克自己做的笔记（铅笔笔记），珍和埃里克第一次对话的笔记（蓝色笔记+黑色笔记）&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;第三遍：&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;珍和埃里克第二次对话的笔记&lt;strong&gt;（&lt;/strong&gt;橙色笔记+绿色笔记）&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;第四遍：&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;珍和埃里克第三次对话的笔记（紫色笔记+红色笔记）&lt;/p&gt;

  &lt;p&gt;&lt;strong&gt;第五遍：&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;珍和埃里克第四次对话的笔记（黑色小写笔记+黑色大写笔记）&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Sat, 21 Dec 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sougua/%E5%BF%92%E4%BF%AE%E6%96%AF%E4%B9%8B%E8%88%B9/</link>
        <guid isPermaLink="true">http://localhost:4000/sougua/%E5%BF%92%E4%BF%AE%E6%96%AF%E4%B9%8B%E8%88%B9/</guid>
      </item>
    
      <item>
        <title>Stochastic block model</title>
        <description>&lt;h2 id=&quot;beta-distribution&quot;&gt;Beta distribution&lt;/h2&gt;

&lt;p&gt;In probability theory and statistics, the beta distribution is a family of continuous probability distributions defined on the interval $[0, 1]$ parametrized by two positive shape parameters, denoted by $\alpha$ and $\beta$, that appear as exponents of the random variable and control the shape of the distribution. It is a special case of the Dirichlet distribution.&lt;/p&gt;

&lt;p&gt;PDF: $\frac{x^{\alpha-1}(1-x)^{\beta-1}}{\mathrm{B}(\alpha, \beta)}$, where $\mathrm{B}(\alpha, \beta)=\frac{\Gamma(\alpha) \Gamma(\beta)}{\Gamma(\alpha+\beta)}$ and $\Gamma$ is the Gamma function.&lt;/p&gt;

&lt;h2 id=&quot;dirichlet-distribution&quot;&gt;Dirichlet distribution&lt;/h2&gt;

&lt;p&gt;$\operatorname {Dir} ({\boldsymbol {\alpha }})$ is a family of continuous multivariate probability distributions parameterized by a vector ${\boldsymbol {\alpha }}$ of positive reals. It is a multivariate generalization of the beta distribution, hence it has an alternative name of multivariate beta distribution (MBD). Dirichlet distributions are &lt;strong&gt;commonly used as prior distributions in Bayesian statistics&lt;/strong&gt;, and in fact the Dirichlet distribution is the conjugate prior of the categorical distribution and multinomial distribution.&lt;/p&gt;

&lt;p&gt;PDF: $\frac{1}{\mathrm{B}(\boldsymbol{\alpha})} \prod_{i=1}^{K} x_{i}^{\alpha_{i}-1}$, where $\mathrm{B}(\boldsymbol{\alpha})=\frac{\prod_{i=1}^{K} \Gamma\left(\alpha_{i}\right)}{\Gamma\left(\sum_{i=1}^{K} \alpha_{i}\right)}$ and $\boldsymbol{\alpha}=\left(\alpha_{1}, \ldots, \alpha_{K}\right)$.&lt;/p&gt;

&lt;h2 id=&quot;stochastic-block-model&quot;&gt;Stochastic block model&lt;/h2&gt;

&lt;p&gt;The stochastic block model is a generative model for random graphs. This model tends to produce graphs containing communities, subsets characterized by being connected with one another with particular edge densities. For example, edges may be more common within communities than between communities. The stochastic block model is important in statistics, machine learning, and network science, where it serves as a useful benchmark for the task of recovering community structure in graph data.&lt;/p&gt;

&lt;p&gt;The stochastic block model takes the following parameters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the number $n$ of vertices&lt;/li&gt;
  &lt;li&gt;a partition of the vertex set ${1,\ldots,n}$ into disjoint subsets ${C_{1},\ldots ,C_{r}}$, called &lt;em&gt;communities&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;a symmetric ${r\times r}$ matrix ${P}$ of edge probabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The edge set is then sampled at random as follows: any two vertices $u \in C_i$ and $v \in C_j$ are connected by an edge with probability $P_{ij}$. An example problem is: given a graph with $n$ vertices, where the edges are sampled as described, recover the groups $C_1,\ldots,C_r$.&lt;/p&gt;

</description>
        <pubDate>Mon, 16 Dec 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/notes/Stochastic-block-model/</link>
        <guid isPermaLink="true">http://localhost:4000/notes/Stochastic-block-model/</guid>
      </item>
    
      <item>
        <title>Dealing with intractable integrals</title>
        <description>&lt;h2 id=&quot;intractable-integrals&quot;&gt;Intractable integrals&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;h3 id=&quot;reference&quot;&gt;Reference&lt;/h3&gt;

  &lt;ol&gt;
    &lt;li&gt;https://ermongroup.github.io/cs228-notes/inference/variational/&lt;/li&gt;
    &lt;li&gt;https://theclevermachine.wordpress.com/2012/09/22/monte-carlo-approximations/.&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;monte-carlo-approximation&quot;&gt;Monte Carlo Approximation&lt;/h3&gt;

&lt;p&gt;Using statistical methods we often run into integrals that take the form:
&lt;script type=&quot;math/tex&quot;&gt;I=\int_{a}^{b} h(x) g(x) d x&lt;/script&gt;
Sometimes such an integral can be evaluated analytically. When a closed form solution does not exist, numeric integration methods can be applied. However, numerical methods quickly become intractable for any practical application that requires more than a small number of dimensions. This is where &lt;strong&gt;Monte Carlo approximation&lt;/strong&gt; comes in.&lt;/p&gt;

&lt;p&gt;Monte Carlo approximation allows us to calculate an estimate for the value of $I$ by transforming the  integration problem into a procedure of sampling values from a tractable probability distribution and calculating the average of those samples.&lt;/p&gt;

&lt;p&gt;If function $g(x)$ fullfills the following two criteria:
&lt;script type=&quot;math/tex&quot;&gt;g(x) \geq 0, x \in(a, b)&lt;/script&gt;
and its integral is finite
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\int_{a}^{b} g(x)=C&lt;\infty %]]&gt;&lt;/script&gt;
then we can define a corresponding probability distribution on the interval $(a, b)$
&lt;script type=&quot;math/tex&quot;&gt;p(x)=\frac{g(x)}{C}&lt;/script&gt;
Then we can restate the original integration as
&lt;script type=&quot;math/tex&quot;&gt;I=C \int_{a}^{b} h(x) p(x) d x=C \mathbb{E}_{p(x)}[h(x)]&lt;/script&gt;
If we can &lt;em&gt;sample&lt;/em&gt; values of $x$ using $p(x)$, then the value of  the original integral $I$ is simply a scaled version of the expected value of the integrand function $h(x)$ calculated using those samples. Turns out that the expected value $\mathbb E_{p(x)}[h(x)]$ can be easily approximated by the sample mean:
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}_{p(x)}[h(x)] \approx \frac{1}{N} \sum_{i}^{N} h\left(x_{i}\right)&lt;/script&gt;
where samples $x_i, i = 1…N$ are drawn independently from $p(x)$. This leads to a simple 4-Step Procedure for performing Monte Carlo approximation to the integral $I$:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Identify $h(x)$&lt;/li&gt;
  &lt;li&gt;Identify $g(x)$ and determine $p(x)$ and $C$&lt;/li&gt;
  &lt;li&gt;Draw $N$ independent samples from $p(x)$&lt;/li&gt;
  &lt;li&gt;Evaluate $I = C \mathbb E[h(x)] \approx \frac{C}{N} \sum_i^N h(x_i)$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The larger the number of samples $N$ we draw, the better our approximation to the actual value of $I$.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h4 id=&quot;example-iint_01-x-ex-d-x&quot;&gt;Example $I=\int_{0}^{1} x e^{x} d x$&lt;/h4&gt;

  &lt;p&gt;We can calculate the closed form solution of this integral using integration by parts:
&lt;script type=&quot;math/tex&quot;&gt;\begin{array}{l}
{u=x, d v=e^{x}} \\ 
{d u=d x, v=e^{x}}
\end{array}&lt;/script&gt;
And the result is
&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
I &amp;=u v-\int v d u = x e^{x}-\int e^{x} d x \\ 
&amp;=x e^{x}-\left.e^{x}\right|_{0} ^{1} =\left.e^{x}(x-1)\right|_{0} ^{1} =0-(-1)=1
\end{aligned} %]]&gt;&lt;/script&gt;
Next we calculate the  Monte Carlo approximation of this integral.&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;indentify $h(x)=x e^{x}$&lt;/li&gt;
    &lt;li&gt;identify $g(x)=1$ and determine the probability distribution function $p(x) \in (a,b) = (0,1)$.&lt;/li&gt;
    &lt;li&gt;According to the definition expression for $p(x)$ given above we detemine $p(x)$ to be $p(x)=\frac{g(x)}{\int_{a}^{b} g(x) d x}=\frac{1}{b-a}$, which is the definition for the uniform distribution $\operatorname{uni}(0,1)$.&lt;/li&gt;
    &lt;li&gt;calculate the Monte Carlo approximation as $I=C \mathbb{E}&lt;em&gt;{p(x)} h(x)\approx \frac{1}{N} \sum&lt;/em&gt;{i=1}^{N} x_{i} e^{x_{i}}$&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;markov-chain-monte-carlo&quot;&gt;Markov chain Monte Carlo&lt;/h3&gt;

&lt;p&gt;Markov chain Monte Carlo (MCMC) methods comprise a class of algorithms for sampling from a probability distribution. By constructing a Markov chain that has the desired distribution as its equilibrium distribution, one can obtain a sample of the desired distribution by recording states from the chain. The more steps that are included, the more closely the distribution of the sample matches the actual desired distribution.&lt;/p&gt;

&lt;p&gt;Most sampling-based inference algorithms are instances of Markov Chain Monte-Carlo (MCMC); two popular MCMC methods are Gibbs sampling and Metropolis-Hastings.&lt;/p&gt;

&lt;h3 id=&quot;variational-inference&quot;&gt;Variational inference&lt;/h3&gt;

&lt;p&gt;Sampling-based methods have several important shortcomings:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Although they are guaranteed to find a globally optimal solution given enough time, it is difficult to tell how close they are to a good solution given the finite amount of time that they have in practice.&lt;/li&gt;
  &lt;li&gt;In order to quickly reach a good solution, MCMC methods require choosing an appropriate sampling technique (e.g. a good proposal in Metropolis-Hastings). Choosing this technique can be an art in itself.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An alternative approach to approximate inference is the &lt;strong&gt;variational family&lt;/strong&gt; of algorithms. The main differences between sampling and variational techniques are that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unlike sampling-based methods, variational approaches will almost never find the globally optimal solution.&lt;/li&gt;
  &lt;li&gt;However, we will always know if they have converged. In some cases, we will even have bounds on their accuracy.&lt;/li&gt;
  &lt;li&gt;In practice, variational inference methods often scale better and are more amenable to techniques like stochastic gradient optimization, parallelization over multiple processors, and acceleration using GPUs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The main idea of variational methods is to cast inference as an optimization problem. Suppose we are given an intractable probability distribution $p$. Variational techniques will try to solve an optimization problem over a class of tractable distributions $Q$ in order to find a $q\in Q$ that is most similar to $p$. We will then query $q$ (rather than $p$) in order to get an approximate solution.&lt;/p&gt;

&lt;h3 id=&quot;variational-bayesian-methods&quot;&gt;Variational Bayesian methods&lt;/h3&gt;

&lt;p&gt;Variational Bayesian methods are a family of techniques for approximating intractable integrals arising in Bayesian inference and machine learning. They are typically used in complex statistical models consisting of observed variables (usually termed “data”) as well as unknown parameters and latent variables, with various sorts of relationships among the three types of random variables, as might be described by a graphical model. As typical in Bayesian inference, the parameters and latent variables are grouped together as “unobserved variables”. Variational Bayesian methods are primarily used for two purposes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To provide an analytical approximation to the posterior probability of the unobserved variables, in order to do statistical inference over these variables.&lt;/li&gt;
  &lt;li&gt;To derive a lower bound for the marginal likelihood (sometimes called the “evidence”) of the observed data (i.e. the marginal probability of the data given the model, with marginalization performed over unobserved variables). This is typically used for performing model selection, the general idea being that a higher marginal likelihood for a given model indicates a better fit of the data by that model and hence a greater probability that the model in question was the one that generated the data. (See also the Bayes factor article.)&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Sun, 15 Dec 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/notes/Dealing-with-intractable-integrals/</link>
        <guid isPermaLink="true">http://localhost:4000/notes/Dealing-with-intractable-integrals/</guid>
      </item>
    
      <item>
        <title>俗世奇人</title>
        <description>&lt;h4 id=&quot;胡子&quot;&gt;《胡子》&lt;/h4&gt;

&lt;p&gt;爱的本质就是生命的相互依赖。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;就这层胡茬，使他忽然感到，往日往事，充溢着勃勃生机的生命，还有习惯了的生活，带着一种挺动人的气息又都回来了。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;雕花烟斗&quot;&gt;《雕花烟斗》&lt;/h4&gt;

&lt;p&gt;前些年失掉的荣誉，像一只跑掉的鸟儿，又带着一连串响亮的鸣叫飞回来了。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;酒婆&quot;&gt;《酒婆》&lt;/h4&gt;

&lt;p&gt;酒鬼们对眼睛里的世界一片模糊，对肚子里的酒却一清二楚，但谁也不肯把这层纸捅破，喝美了也就算了。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;逼来的春天&quot;&gt;《逼来的春天》&lt;/h4&gt;

&lt;p&gt;冬天与春天的界限是瓦解。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;冰的坍塌不是冬的风景，而是隐形的春所创造的第一幅壮丽的图画。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;春天不是由远方来到眼前，不是由天外来到人间；它原是深藏在万物的生命之中的，它是从生命深处爆发出来的，它是生的欲望、生的能源与生的激情。它永远是死亡的背面。惟此，春天才是不可遏制的。它把酷烈的严冬作为自己的序曲，不管这序曲多么漫长。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;苦夏&quot;&gt;《苦夏》&lt;/h4&gt;

&lt;p&gt;夏天的最后一刻，总是它酷热的极致。我明白了，它是耗尽自己的一切，才显示出夏的无边的威力。生命的快乐是能量淋漓尽致地发挥。但谁能像它这样，用一种自焚的形式，创造出这火一样辉煌的顶点？&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;致大海&quot;&gt;《致大海》&lt;/h4&gt;

&lt;p&gt;你拿的工资可是人民给的，不是领导给的。领导的工资也是人民给的。拿了人民的钱就得为人民说话，不要怕！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;那幅画我可是特意为您画得那么小，您的房间太窄，没有挂大画的墙壁。但是您告诉我：“只要是海，都是无边的大。”&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;记韦君宜&quot;&gt;《记韦君宜》&lt;/h4&gt;

&lt;p&gt;我不知道为什么，对一个人深入的回忆，非要到他逝去之后。难道回忆是被痛苦带来的吗？&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;回忆不是痛苦的，而是寂寥人间一种暖意的安慰。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 15 Dec 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sougua/%E4%BF%97%E4%B8%96%E5%A5%87%E4%BA%BA/</link>
        <guid isPermaLink="true">http://localhost:4000/sougua/%E4%BF%97%E4%B8%96%E5%A5%87%E4%BA%BA/</guid>
      </item>
    
      <item>
        <title>不识</title>
        <description>&lt;p&gt;####11.12&lt;/p&gt;

&lt;p&gt;有很长一段时间里，脑子里总是处于一种混沌的状态。不知道我所过的生活究竟是什么。每个星期重复的行程像早就刻在铁板上的程序，永远在往复旋转。&lt;/p&gt;

&lt;p&gt;在生活里遇到这样那样的问题，然后发现自己早已失去了刚上大学时候那种永远在线的上进心。变得对一切都无动于衷，不知道是因为想要逃避不甘愿的心情，还是为了活着更轻松。&lt;/p&gt;

&lt;p&gt;昨天晚上突然买到回家的机票以后，突然之间寒假就可以回家了。被难以言喻的幸福感包容。甚至重拾了对生活的信心，开始想要好好努力。&lt;/p&gt;

&lt;p&gt;可能是在无意中发现了自己的本质吧，人终究是毫不起眼的。但是也有所爱的人值得为之奋斗。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;123&quot;&gt;12.3&lt;/h4&gt;

&lt;p&gt;这段时间好像魔怔了，一直精神失常，情绪低沉，对身边的一切都漠不关心。但是感恩节从北密回来以后魔怔突然被治愈了。夜深时分突然惊醒，感到格外凄清也格外安宁。断断续续中会因为一些小小的细节继而想起好几个月以前的事情。想起当初错误的撒气和不负责任的埋怨。心中有愧，但是因为时间隔得太久远，又很久没有联系，于是失去了提起它的契机。于是只好在心里默默说声抱歉。前段时间因为感受不到生活的真实而暴躁不安。有好几次想要记录下内心的烦躁，最后每次都是打开了页面，却最终没有落笔。在键盘面前踟蹰了一会，还是放弃了。有些时候，人连一个说服自己的理由也懒得找。但是，现在终于能脚踏实地的感受到生活的存在了。不知道是因为写出了一直害怕且逃避的代码，还是因为如愿改变了对最讨厌的一门课的态度，还是因为突发奇想开始看《世界美术二十讲》。但是无论如何，在这个学期即将结束的最后两个星期，突然恢复了对生活的感知能力。有一种大病初愈的感觉，和内心某个叛逆的声音和解的感觉。在逃跑了很长一段时间以后最终又回到了从前喜欢的事情上。&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/feihua/%E4%B8%8D%E8%AF%86/</link>
        <guid isPermaLink="true">http://localhost:4000/feihua/%E4%B8%8D%E8%AF%86/</guid>
      </item>
    
      <item>
        <title>局外人</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;阿尔贝·加缪(Albert Camus). 《局外人》 上海译文出版社. Kindle Edition.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;它真正的病是衰老，而衰老是治不好的。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他全神贯注地盯着我，带点儿伤心的神情，低声说：“我从没有见过像您这样冥顽不化的灵魂，所有来到我面前的犯人，见了这个十字架，都会痛哭流涕。”我正想回答说，这正是因为他们都是罪犯，但我立刻想到我也跟他们一样。罪犯这个念头，我一直还习惯不了。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;在入狱之初，最叫我痛苦难受的是我还有自由人意识。例如，我想到海滩上去，想朝大海走去，想像最先冲到我脚下的海浪的声响，想像身体跳进海水时的解脱感，这时，却突然意识到自己是禁闭在牢房的四壁之中。但这种不适应感只持续了几个月，然后，我就只有囚犯意识了。我期待着每天在院子里放风或者律师来和我晤谈。其余的时间，我也安排得很好。我常想，如果要我住在一棵枯树的树干里，什么事都不能做，只能抬头望望天空的流云，日复一日，我逐渐也会习惯的，我会等待着鸟儿阵阵飞起，云彩聚散飘忽，就像我在牢房里等着我的律师戴着奇特的领带出现，或者就像我在自由的日子里耐心地等到星期六而去拥抱玛丽的肉体。更何况，认真一想，我并没有落到在枯树干里度日的地步。比我更不幸的人还多着呢，不过，这是妈妈的思维方式，她常这么自宽自解，说到头来人什么都能习惯。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;一个人即使只生活过一天，他也可以在监狱里待上一百年而不至于难以度日，他有足够的东西可供回忆，决不会感到烦闷无聊。从某种意义上来说，这也是一种愉快。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;我过去在书里读到过，说人在监狱里久而久之，最后就会失去时间观念。但是，这对我来说，并没有多大意义。我一直不理解，在何种程度上，既可说日子漫漫难挨，又可说苦短无多。日子，过起来当然就长，但是拖拖拉拉，日复一日，年复一年，最后就混淆成了一片。每个日子都丧失了自己的名字。对我来说，只有“昨天”与“明天”这样的字，才具有一定的意义。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;我觉得，我的样子显得很严肃，即使是在我试图微笑的时候也是如此。我晃了晃那饭盒，又微笑了一下，但照出来的仍是那副严肃而忧愁的神情。天黑了，这是我不愿意谈到的时间，是无以名状的时间，这时，夜晚的嘈杂声从监狱各层升起，而后又复归于一片寂静。我走近天窗，借着最后的亮光，又照了照自己的脸。神情老是那么严肃。这有什么奇怪呢？既然那个时刻我一直就很严肃。但这时，我几个月来第一次清晰地听见我自己说话的声音。我辨识出这就是好久以来一直在我耳边回响的声音，我这才明白，在这一段日子里，我一直在自言自语。于是，我回想起妈妈葬礼那天女护士说过的话。不，出路是没有的，没有人能想像出监狱里的夜晚是怎么样的。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;我只是觉得自己似乎是在电车上，对面坐位上有一排不认识的乘客，他们审视着新上车的人，想在他们身上发现有什么可笑之处。我马上意识到我这种联想很荒唐，因为我面前这些人不是在找可笑之处，而是在找罪行。不过，两者的区别也并不大，反正我就是这么想的。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;“这就是这场审讯的形象，所有一切都是真的，但又没有任何东西是真的！”&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;对过去生活的种种回忆突然涌入我的脑海，那生活已经不属于我了，但我从那里确曾得到过我最可怜、最难以忘怀的快乐，如夏天的气味、我所热爱的街区、傍晚时的天空、玛丽的笑声与裙子。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;世人对这类问题必须经常关注，因为谁也不知道会有什么事情落在自己头上。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;我听见自己的心在跳动，我不能想像伴随着我这么多年的心跳声，有朝一日会停止。我从未有过真正的想像力。但我还是试图想像出心跳声不再传到脑子里的那短暂的片刻。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;一种阴暗的气息从我未来前途的深处向我扑面而来，它穿越了尚未到来的岁月，所到之处，使人们曾经向我建议的所有一切彼此之间不再有高下优劣的差别了，未来的生活也并不比我以往的生活更真切实在。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;田野上万籁作响，直传到我的耳际。夜的气味， 土地的气味，海水的气味，使我两鬓生凉。这夏夜奇妙的安静像潮水一样浸透了我的全身。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;掏空了我的七情六欲一样，现在我面对着这个充满了星光与默示的夜，第一次向这个冷漠的世界敞开了我的心扉。我体验到这个世界如此像我，如此友爱融洽，觉得自己过去曾经是幸福的，现在仍然是幸福的。为了善始善终，功德圆满，为了不感到自己属于另类，我期望处决我的那天，有很多人前来看热闹，他们都向我发出仇恨的叫喊声。&lt;/p&gt;
</description>
        <pubDate>Tue, 12 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sougua/%E5%B1%80%E5%A4%96%E4%BA%BA/</link>
        <guid isPermaLink="true">http://localhost:4000/sougua/%E5%B1%80%E5%A4%96%E4%BA%BA/</guid>
      </item>
    
      <item>
        <title>穆斯林的葬礼</title>
        <description>&lt;p&gt;她夜夜都梦见这座门楼、这所院子，梦见院子里的天空，梦见天上的月亮，梦见那一双永远也不能忘记的眼睛，梦见那一声声牵心动腑的呼唤……&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;天上有明月，年年照相思。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;她夜夜沉醉在梦中。梦把空间缩短了，梦把时间凝固了，梦把世界净化了。梦中没有污秽，没有嘈杂，没有邪恶；梦中没有分离，没有创伤，没有痛苦；梦中只有柔和的月色，只有温馨的爱；梦使她永远年轻，使她不愿醒来。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;“克尔白！您去朝克尔白？”梁亦清又着着实实地吃了一惊。克尔白是穆斯林尊贵的天房，远在阿拉伯的圣地麦加，全世界的穆斯林一日五次的礼拜都朝着那个方向；每一个穆斯林一生之中，如果条件许可应该前往克尔白朝觐一次。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他在人世间走了很久很久，好像就是为了这一个美妙的瞬间，他感到了从未体味过的满足、兴奋和欢乐，仿佛他手中捧着的不是一只玉碗，而是天外飞来的精灵，和他的心相通了。他陶醉了，麻木了，把身边的一切，把他自己都忘记了，被玉魔摄住了魂魄……&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;过生日无非是表达一点美好的愿望吧。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;事业的追求，并不一定要什么头衔和称号来满足，你爱上了一种东西，愿意用全部心血去研究它，掌握它，从中得到了乐趣，并且永远也不舍得丢弃它，这就是事业心，是比什么都重要的……”&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;眼泪这东西，有时能起到极其神奇的作用，能把持有截然不同的观点的人稀里糊涂地拢在一起，把迂腐陈旧的意识变得温暖感人，把生机勃勃的新兴幼芽儿在爱抚之中扼杀！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;如果别人一说你不行，你就回家不干了，那恰恰证明你真的不行！你难道就这样无囊无气吗？回去有脸见江东父老吗？&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;或者说他在老师的身上才认识了“父亲”的含义：爱得那么深，教得那么细，管得那么严。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;有血性的人，决不曲意求得别人重视，也不怕别人忽视。’别人的误解、偏见并不可怕，可怕的是失去了自信；如果你是自信的，就什么话都不用说了。真理从来都是最简单、最朴素的，除了它本身之外，并不需要额外地加以解释，正如一个真正美的人，任何附加的首饰都是多余的！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;做父亲的心是用语言难以表达的，无论是哪国语言。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;新的生活图景填补了那个缺憾，人生向她打开了另一扇通往未来的大门，由于生活清苦和感情压抑而黯淡的脸上出现了过去难得一见的光彩。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他认为“失恋”是一种耻辱，并不像一些大知识分子那样还能从中寻找出什么诗意。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;尤其令人遗憾的是，莎翁对她的结局无计可施，就让她疯，让她死，这也是使我不能接受的！她死得倒是很别致，漂在明镜似的水上，头戴奇异的花环：毛茛、荨麻、雏菊、长颈兰，轻轻地唱着古老的歌……是的，很有诗意，很美，可是，这美还有什么意思呢？我不能欣赏这病态的美、死亡的美，我要看到的是健康的人生，那才是真正的美、生命的美！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;他不敢让女儿看他的眼睛，怕她透过父亲的笑容，看到埋藏在里面的深深的痛苦。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;往日的情景，清晰地浮现在眼前，那不是梦，那是真真切切的现实，是她亲身经历过的，永远也不会忘的。十七八岁少女的心，纯净得像一面镜子，印在上面的影像，将会记一辈子……&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;只有谎言才拼命鼓吹，唯恐别人不相信。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;人的内心深处总有属于自己的一点儿隐秘，新月也有，一种飘忽不定的思绪，常常搅扰着她的心，却又难以捉摸，难以把握，像一个猜不透的谜，常常在夜深人静之时缠绕在脑际，苦思而不得其解，久久难以入睡。这使她烦恼，使她痛苦，却又不能求助于任何人。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;每一个收藏者都希望自己是它们的最后一个主人，为了使自己拥有这个权利而互相争夺，从而使它们的身价倍增。而实际上，谁也不是它们的永久的主人，而只是暂时的守护者。玉寿千年，人生几何？高价抢购，精心收藏，到头来却不知落入何人之手！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;看来爱神在和死神赛跑，小伙子们和姑娘们要抢在战争前面享受他们应得的爱情！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;课堂上，讲授英国文学史的教授在头头是道地分析乔叟的长诗《善良女子的故事》，学生却在下面议论希特勒和墨索里尼的阴谋。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;夜尽了，天亮了，地下室铁床上的五个人都爬起来了，惺忪睡眼对望着，都有一种莫名其妙的幸运感：又活过了一天。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;每个人都有自己的心灵，自己的情感，谁也不能代替谁。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;给予我的已经太多了，怎么还能奢望得到您的爱情？您是一个健全的人，完美无缺的人，前途光辉灿烂的人；而我，却命里注定不能再返回事业之路，不能再陪伴您度过有意义的人生，有什么理由在您那负有重任的双肩上再增加负担？又怎么忍心拖着您和我一起坠入深渊！原谅我，我不能接受您的爱情，仅仅做师生和朋友已经足够了，让我们永远记住这高尚纯洁的情感！也许，我们之间并不存在爱情，爱情是什么？每个人都有不同的答案，但我想，爱情总不等于同情、怜悯和自我牺牲吧？&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;我珍藏着美好的过去，并将在千遍万遍的回忆中度过自己的余生，直到这颗不可救药的心脏停止跳动。&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;在跨进这道门槛之前自认为顺理成章的一切，跨进门槛后都变得荒谬绝伦。当他重新面对妻子的时候，才突然发觉原来妻子对他怀着这么强烈的爱，而在过去的岁月里却被他漠视了，正因为这样，他才会在变换了环境之后像一个初涉世事的少年那样去认识、去经历另一场爱！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;十年认识了一个人，三十年懂得了人生，这不也是付出的岁月换取的收获吗？她比过去清醒了，不再糊涂了！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;没关系；被人妒忌也是一种幸福啊！&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;“楚老师，鲁迅为什么要写《起死》？”“也许，他要唤醒沉睡的人生……”“庄子为什么要给五百年前的骷髅‘起死’？”“也许，是要他重新生活一次。人生虽然艰难，生命毕竟可贵。庄子认为，人生应该像鲲鹏展翅，扶摇而上九万里，绝云气，负青天！”&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Nov 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/sougua/%E7%A9%86%E6%96%AF%E6%9E%97%E7%9A%84%E8%91%AC%E7%A4%BC/</link>
        <guid isPermaLink="true">http://localhost:4000/sougua/%E7%A9%86%E6%96%AF%E6%9E%97%E7%9A%84%E8%91%AC%E7%A4%BC/</guid>
      </item>
    
  </channel>
</rss>
